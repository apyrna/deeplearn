{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron Multi-Capa con PyTorch\n",
    "=================================\n",
    "\n",
    "Vamos a ver como implementar un perceptron multicapa (MLP) con una sola capa oculta en torch de varias maneras. Las distintas implementaciones van a ir desde más bajo nivel al más alto, para que se entienda que es lo que está haciendo la librería internamente.\n",
    "\n",
    "Comencemos por definir el problema y la arquitectura de la red. Vamos a tratar de que la red aprenda la forma general del problema de XOR, es decir, el O-Exclusivo para más de dos variables, o también conocido como el problema de paridad. \n",
    "Se lo llama problema de paridad porque es esquivalente a contar la cantidad de 1s en un número binario, y el resultado depende de si esta cantidad fue par o impar. (e.g.  00→0, 01→1, 10→1, 11→0, 1001→0, 111011→1) \n",
    "Este problema es especialmente difícil para los modelos de aprendizaje automático porque el cambio en cualquier variable de entrada también cambia la salida.\n",
    "En este caso vamos a considerar 8 variables de entrada, y en lugar de usar variables binarias (0,1), vamos a usar variables bipolares (-1,1). El valor objetivo lo podemos calcular sencillamente como el producto de las variables de entrada.\n",
    "\n",
    "Empecemos importando la librería, definiendo algunas variables del problema y la arquitectura, y creando el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "P = 100    # Cantidad de instancias de datos.\n",
    "N = 8      # Cantidad de unidades en la capa de entrada.\n",
    "H = N+1    # Cantidad de unidades en la capa oculta.\n",
    "M = 1      # Cantidad de unidades en la capa de salida.\n",
    "\n",
    "x = torch.randn( P, N).sign()\n",
    "z = torch.prod( x, dim=1).view(P,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo siguiente va a ser crear nuestro modelo. Para esto vamos a definir explicitamente las matrices de pesos para las capas oculta y de salida. Va a ser necesario también indicar que queremos que sobre estos tensores se cualculen automáticamente los gradientes.\n",
    "Adicionalmente vamos a necesitar también un tensor poblado con 1s para concatenar con las otras neuronas para que sirvan de *unidad umbral*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.randn( N+1, H, requires_grad=True)\n",
    "w2 = torch.randn( H+1, M, requires_grad=True)\n",
    "\n",
    "bias = torch.ones( P, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente el entrenamiento lo vamos a realizar en modo *batch*. En *h* e *y* vamos a tener los resultados de la activación de las unidades de la capa oculta y de salida respectivamente, y en *error* vamos a calcular la suma de las diferencias cuadradas entre la salida y los objetivos.\n",
    "Este *error* es evidentemente la función de costo que queremos minimizar, y torch utiliza las operaciones necesarias para calcularlo (incluyendo las de *y*) para construir el grafo de computo para poder hacer los gradientes automáticos en *w1* y *w2*.\n",
    "Los gradientes se calculan al utilizar el método *error.backward()*, y los guarda en *w1.grad* y *w2.grad*. Para poder aplicar estos gradientes a los pesos debemos indicar que esas operaciones no van a formar parte de grafo de computo. Esto es lo que hace con el *no_grad*. Finalmente después de aplicarlos los reseteo con *grad.zero_()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.08005979537963867\n",
      "2000 0.08005378723144531\n",
      "3000 0.08004894256591796\n",
      "4000 0.08004493713378906\n",
      "5000 0.08004156112670899\n",
      "6000 0.0800386619567871\n",
      "7000 0.08003614425659179\n",
      "8000 0.08003395080566406\n",
      "9000 0.0800320053100586\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "t, e = 0, 1.\n",
    "while e>0.01 and t<9999:\n",
    "    h = torch.cat( (x,bias), dim=1).mm(w1).tanh()\n",
    "    y = torch.cat( (h,bias), dim=1).mm(w2).tanh()\n",
    "    error = (y-z).pow(2).sum()\n",
    "    error.backward()\n",
    "    with torch.no_grad():\n",
    "        w1 -= lr*w1.grad\n",
    "        w2 -= lr*w2.grad\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()\n",
    "    e = error.item()/P\n",
    "    t += 1\n",
    "    if t%1000==0:\n",
    "        print(t,e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien una de las grandes ventajas de **pytorch** es que nos permite tener el control suficiente como para poder hacer todas estas operaciones a mano, también es práctico tener funciones, métodos y clases predefinidas a un nivel más abstracto. Para esto existe el módulo **torch.nn** que implementa varias clases relacionadas directamente con redes neuronales.\n",
    "En nuestro caso, como lo que nos interesa es implementar un modelo con una arquitectura *feedforward*, podemos utilizar la clase *torch.nn.Sequential*. Esta clase agregar capas cuya activación se propaga solo hacia adelante, secuencialmente.\n",
    "Para definir los elementos del perceptrón multicapa vamos a usar la clase *torch.nn.Linear* que permite crear las pesos completamente conectados entre dos capas (incluyendo los umbrales), y la clase *torch.nn.Tanh* como función de activación. Notar que por tratarse de una clase, y no una función, *Tanh* está escrito con mayúscula; la función *tanh* existe también dentro de la librería escrita con minúscula.\n",
    "Finalmente vamos a usar una de las funciones de costo de la librería que es el error cuadrático medio (*MSELoss*), y si queremos mantener el mismo tipo de error que estábamos calculando antes inclusive podemos indicar que el lugar del promedio queremos la suma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(        # Seq es feedforward.\n",
    "        torch.nn.Linear( N, H),     # Linear son los pesos.\n",
    "        torch.nn.Tanh(),            # Tanh es la activacion.\n",
    "        torch.nn.Linear( H, M),     # Linear incluye los bias.\n",
    "        torch.nn.Tanh() )\n",
    "\n",
    "costf = torch.nn.MSELoss( reduction='sum')  # Puedo usar la suma.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto me permite simplificar y escribir de forma un poco más clara el ciclo de entrenamiento.  Sin embargo todavía necesito actualizar los pesos con sus correspondiente gradientes a mano. Como estos pesos y gradientes ahora se encuentran en lo profundo del objeto model para accederlos tengo que usar el método *parameters* que me devuelve iterativamente todos los tensores con parámetros entrenables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1306116485595703\n",
      "100 0.07468906402587891\n",
      "200 0.04669327259063721\n",
      "300 0.04333900928497315\n",
      "400 0.04209674835205078\n",
      "500 0.04150144577026367\n",
      "600 0.04116389274597168\n",
      "700 0.04094815731048584\n",
      "800 0.040798578262329105\n",
      "900 0.040688815116882326\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "for t in range(999):\n",
    "    y = model( x)                   # Puedo usarlo como funcion.\n",
    "    model.zero_grad()               # Reseteo los grad antes de back.\n",
    "    error = costf( y, z)\n",
    "    error.backward()\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= lr * param.grad\n",
    "    if not t%100:\n",
    "        print( t, error.item()/P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que tanto *model* como *costf* son objetos y sin embargo están siendo utilizados como funciones. Esta es una particularidad de **pytorch** que es práctica pero puede resultar confusa al comienzo.\n",
    "Otras diferencias con la forma anterior es que ahora podemos resetear los gradientes directamente con *zero_grad* y que, a pesar de que el error sigue siendo un escalar, torch devuelve siempre un tensor, en este caso con un solo elemento, por lo cual para imprimirlo más claramente podemos usar *error.item()*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero para poder aprovechar realmente el potencial de la librería lo mejor es crear una nueva clase con la arquitectura deseada para el modelo. Esto se hace derivando la nueva clase de *torch.nn.Module*. Cuando se crea una clase de este tipo hay que tener en cuenta dos cosas:\n",
    "1. Cualquier miembro de la clase que también sea derivado de *Module* integrará sus parámetros con los del modelo recursivamente.\n",
    "2. La respuesta del modelo se determina implementando el método *forward*. (Este es el que es llamado cuando se le pasan parámetros al objeto como si fuera una función)\n",
    "\n",
    "Veamos como quedaría implementado el perceptron multicapa de esta forma y después aclaramos cada punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp( torch.nn.Module):                    # Module para hacer modelos propios.\n",
    "    def __init__( _, isize, hsize, osize):      # Uso _ en lugar de self.\n",
    "        super().__init__()\n",
    "        _.l1 = torch.nn.Linear( isize, hsize)   # Params de modelo.\n",
    "        _.l2 = torch.nn.Linear( hsize, osize)\n",
    "\n",
    "    def forward( _, x):\n",
    "        h = torch.tanh( _.l1( x))               # Grafo de computo.\n",
    "        y = torch.tanh( _.l2( h))\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al constructor __init__ le paso como parámetros la dimensión de las capas de entrada, oculta, y salida. Con estos valores creo las conexiones para las capas con *Linear* que quedan como los miembros *l1* y *l2*. Como *Linear* también es derivado de *Module* los parámetro entrenables de estos objetos también van ser parte de este modelo, es decir, son devueltos si se itera usando la función *parameters*.  De la misma forma, si *mlp* fuera utilizado como miembro en otra clase derivada de *Module* sus parámetros entrenables también pasaría a formar parte de esta (i.e. recursivo).\n",
    "\n",
    "Con el método *forward* se determina la respuesta del modelo al recibir datos de entrada *x*. Esto da bastante libertad para calcular la salida de la red, inclusive hasta utilizando ciclos o condicionales, pero se deben utilizar todas funciones propias de *torch* porque este calculo formará parte de el grafo de cómputo para calcular los gradientes automáticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, ahora que *torch* va a saber cúales son los parámetros entrenables y cómo actualizarlos, podemos también utilizar uno de los métodos de aprendizaje propios de la librería. En este caso el *Stochastic Gradient Descent*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp( N, H, M)\n",
    "optim = torch.optim.SGD( model.parameters(), lr=0.01)\n",
    "costf = torch.nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y reescribiendo el ciclo de entrenamiento..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.8892418146133423\n",
      "2000 0.8439221978187561\n",
      "3000 0.620249330997467\n",
      "4000 0.40158817172050476\n",
      "5000 0.2635127007961273\n",
      "6000 0.1668662130832672\n",
      "7000 0.11692226678133011\n",
      "8000 0.08941445499658585\n",
      "9000 0.0742102861404419\n"
     ]
    }
   ],
   "source": [
    "t, E = 0, 1.\n",
    "while E>=0.01 and t<9999:\n",
    "    y = model( x)\n",
    "    optim.zero_grad()                       # Optim sabe que resetear.\n",
    "    error = costf( y, z)\n",
    "    error.backward()\n",
    "    optim.step()                            # step aplica los gradientes.\n",
    "    E = error.item()\n",
    "    t += 1\n",
    "    if t%1000==0:\n",
    "        print( t, E)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En donde puedo seguir siempre los mismos pasos, independientemente del modelo que esté entrenando, la función de costo que esté tratando de minimizar, o la estrategia de minimización que haya elegido. Y los pasos clave son:\n",
    "1. Obtener una respuesta del modelo: *y = model( x)*\n",
    "2. Inicializar los gradientes: *optim.zero_grad()*\n",
    "3. Calcular el costo: *error = costf( y, z)*\n",
    "4. Calcular los gradientes: *error.backward()*\n",
    "5. Aplicar los gradientes: *optim.step()*\n",
    "\n",
    "Esta misma estratégia va a ser central para el entrenamiento de todos los modelos y espero que con el desarrollo paso a paso que fuimos haciendo acá haya quedado claro qué está pasando en cada uno de estos pasos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
